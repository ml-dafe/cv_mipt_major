{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T18:07:49.069730Z",
     "start_time": "2020-09-14T18:07:48.682107Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import cv2\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Часть 1: Свертки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация\n",
    "\n",
    "В этом разделе вы реализуете две версии свертки:\n",
    "- `conv_nested`\n",
    "- `conv_fast`\n",
    "\n",
    "Сначала запустите нижеуказанную кодовую ячейку, чтобы загрузить изображение для работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T18:07:49.559487Z",
     "start_time": "2020-09-14T18:07:49.423858Z"
    }
   },
   "outputs": [],
   "source": [
    "# Open image as grayscale\n",
    "img = cv2.imread('img/dog.jpg', 0)\n",
    "\n",
    "# Show image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь реализуем функцию **`conv_nested`** в **`filters.py`**. Это наивная реализация convolution, использующая 4 вложенных for-loops. В качестве входа и выхода она берет изображение $f$ и ядро $h$, которое имеет ту же форму, что и входное изображение. Запуск этой реализации должен занять несколько секунд.\n",
    "\n",
    "*- Подсказка: Возможно, будет проще реализовать $(h*f)$*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала мы протестируем вашу функцию `conv_nested` на простом входе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T18:03:49.740708Z",
     "start_time": "2020-09-14T18:03:49.632020Z"
    }
   },
   "outputs": [],
   "source": [
    "from filters import conv_nested\n",
    "\n",
    "# Simple convolution kernel.\n",
    "kernel = np.array(\n",
    "[\n",
    "    [1,0,1],\n",
    "    [0,0,0],\n",
    "    [1,0,0]\n",
    "])\n",
    "\n",
    "# Create a test image: a white square in the middle\n",
    "test_img = np.zeros((9, 9))\n",
    "test_img[3:6, 3:6] = 1\n",
    "\n",
    "# Run your conv_nested function on the test image\n",
    "test_output = conv_nested(test_img, kernel)\n",
    "\n",
    "# Build the expected output\n",
    "expected_output = np.zeros((9, 9))\n",
    "expected_output[2:7, 2:7] = 1\n",
    "expected_output[5:, 5:] = 0\n",
    "expected_output[4, 2:5] = 2\n",
    "expected_output[2:5, 4] = 2\n",
    "expected_output[4, 4] = 3\n",
    "\n",
    "# Plot the test image\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(test_img)\n",
    "plt.title('Test image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot your convolved image\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(test_output)\n",
    "plt.title('Convolution')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot the exepected output\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(expected_output)\n",
    "plt.title('Exepected output')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте протестируем вашу функцию `conv_nested` на реальном изображении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_nested(image, kernel):\n",
    "\n",
    "    \"\"\"A naive implementation of convolution filter.\n",
    "\n",
    "    This is a naive implementation of convolution using 4 nested for-loops.\n",
    "    This function computes convolution of an image with a kernel and outputs\n",
    "    the result that has the same shape as the input image.\n",
    "\n",
    "    Args:\n",
    "        image: numpy array of shape (Hi, Wi).\n",
    "        kernel: numpy array of shape (Hk, Wk).\n",
    "\n",
    "    Returns:\n",
    "        out: numpy array of shape (Hi, Wi).\n",
    "    \"\"\"\n",
    "\n",
    "    Hi, Wi = image.shape\n",
    "    Hk, Wk = kernel.shape\n",
    "    out = np.zeros((Hi, Wi))\n",
    "\n",
    "    image = np.pad(image, Hk // 2)\n",
    "    \n",
    "    for i in range(Hi):\n",
    "        for j in range(Wi):\n",
    "            for k in range(Hk):\n",
    "                for l in range(Wk):\n",
    "                    out[i, j] += image[i + k, j + l] * kernel[Hk - 1 - k, Wk - 1 - l]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T18:01:30.630536Z",
     "start_time": "2020-09-14T18:01:30.138117Z"
    }
   },
   "outputs": [],
   "source": [
    "# from filters import conv_nested\n",
    "\n",
    "# Simple convolution kernel.\n",
    "# Feel free to change the kernel to see different outputs.\n",
    "kernel = np.array(\n",
    "[\n",
    "    [1,0,-1],\n",
    "    [2,0,-2],\n",
    "    [1,0,-1]\n",
    "])\n",
    "\n",
    "out = conv_nested(img, kernel)\n",
    "# out = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "# Plot original image\n",
    "plt.subplot(221), plt.imshow(img), plt.title('Original'), plt.axis('off')\n",
    "\n",
    "# Plot your convolved image\n",
    "plt.subplot(223), plt.imshow(out), plt.title('Convolution'), plt.axis('off')\n",
    "\n",
    "# Plot what you should get\n",
    "solution_img = cv2.imread('img/convoluted_dog.jpg', 0)\n",
    "plt.subplot(224), plt.imshow(solution_img), plt.title('What you should get'), plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, solution_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем более эффективный вариант свертки с использованием операций с массивами в numpy. Как показано в лекции, свертку можно рассматривать как скользящее окно, которое вычисляет сумму значений пикселей, взвешенных перевернутым ядром. Более быстрая версия: i) будет иметь нулевое изображение, ii) перевернёт ядро по горизонтали и вертикали, и iii) вычислит взвешенную сумму окрестностей в каждом пикселе.\n",
    "\n",
    "Во-первых, реализовать функцию **`zero_pad`** в **`filters.py`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T18:01:46.772903Z",
     "start_time": "2020-09-14T18:01:46.664168Z"
    }
   },
   "outputs": [],
   "source": [
    "from filters import zero_pad\n",
    "\n",
    "pad_width = 20 # width of the padding on the left and right\n",
    "pad_height = 40 # height of the padding on the top and bottom\n",
    "\n",
    "padded_img = zero_pad(img, pad_height, pad_width)\n",
    "print(padded_img.shape)\n",
    "\n",
    "\n",
    "# Plot your padded dog\n",
    "plt.subplot(121), plt.imshow(padded_img), plt.title('Padded dog'), plt.axis('off')\n",
    "\n",
    "# Plot what you should get\n",
    "solution_img = cv2.imread('img/padded_dog.jpg', 0)\n",
    "plt.subplot(122), plt.imshow(solution_img), plt.title('What you should get'), plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, выполните функцию **`conv_fast`** в **`filters.py`** с помощью `zero_pad`. Запустите код ниже, чтобы сравнить результаты по двум реализациям. `conv_fast` должна работать значительно быстрее, чем `conv_nested`.  \n",
    "В зависимости от вашей реализации и компьютера, `conv_nested` должен занять несколько секунд и `conv_fast` должен работать примерно в 5 раз быстрее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T18:01:48.366025Z",
     "start_time": "2020-09-14T18:01:48.272212Z"
    }
   },
   "outputs": [],
   "source": [
    "from filters import conv_fast\n",
    "\n",
    "t0 = time()\n",
    "out_fast = conv_fast(img, kernel)\n",
    "t1 = time()\n",
    "out_nested = conv_nested(img, kernel)\n",
    "t2 = time()\n",
    "\n",
    "# Compare the running time of the two implementations\n",
    "print(\"conv_nested: took %f seconds.\" % (t2 - t1))\n",
    "print(\"conv_fast: took %f seconds.\" % (t1 - t0))\n",
    "\n",
    "# Plot conv_nested output\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(out_nested)\n",
    "plt.title('conv_nested')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot conv_fast output\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(out_fast)\n",
    "plt.title('conv_fast')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание со звездочкой\n",
    "\n",
    "Разработайте более быструю версию свертки и реализуйте **`conv_faster`** в **`filters.py`**. Вы заработаете дополнительный балл в том случае, если `conv_faster` будет работать быстрее (с достаточным запасом), чем `conv_fast` **и** выдаст тот же результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T18:01:50.398522Z",
     "start_time": "2020-09-14T18:01:50.303943Z"
    }
   },
   "outputs": [],
   "source": [
    "from filters import conv_faster\n",
    "\n",
    "t0 = time()\n",
    "out_fast = conv_fast(img, kernel)\n",
    "t1 = time()\n",
    "out_faster = conv_faster(img, kernel)\n",
    "t2 = time()\n",
    "\n",
    "# Compare the running time of the two implementations\n",
    "print(\"conv_fast: took %f seconds.\" % (t1 - t0))\n",
    "print(\"conv_faster: took %f seconds.\" % (t2 - t1))\n",
    "\n",
    "# Plot conv_nested output\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(out_fast)\n",
    "plt.title('conv_fast')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot conv_fast output\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(out_faster)\n",
    "plt.title('conv_faster')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Часть 2: Кросс-корреляция\n",
    "\n",
    "Кросс-корреляция двух 2D сигналов $f$ и $g$ определяется следующим образом:\n",
    "$$(f\\star{g})[m,n]=\\sum_{i=-\\infty}^\\infty\\sum_{j=-\\infty}^\\infty f[i,j]\\cdot g[m-i,n-j]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка шаблона с помощью кросс-корреляцией \n",
    "\n",
    "Предположим, что ты продавщица в продуктовом магазине. Одна из ваших обязанностей - периодически проверять полки и складировать их всякий раз, когда есть распроданные товары. Вы устали от этой кропотливой работы и решили построить систему компьютерного зрения, которая отслеживает предметы на полке.\n",
    "\n",
    "К счастью, в CS131 вы узнали, что для сопоставления шаблонов можно использовать кросс-корреляцию: шаблон $g$ умножается на регионы с большим изображением $f$, чтобы измерить, насколько каждый регион похож на шаблон.\n",
    "\n",
    "Шаблон товара (`template.jpg`) и изображение полки (`shelf.jpg`) предоставляются. Мы будем использовать кросс-корреляцию, чтобы найти товар на полке.\n",
    "\n",
    "Реализуйте функцию **`cross_correlation`** в **`filters.py`** и запустите код ниже.\n",
    "\n",
    "*- Подсказка: Вы можете использовать функцию `conv_fast`, которую вы реализовали в предыдущем вопросе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load template and image in grayscale\n",
    "img = cv2.imread('img/shelf.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_grey = cv2.imread('img/shelf.jpg', 0)\n",
    "temp = cv2.imread('img/template.jpg')\n",
    "temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "temp_grey = cv2.imread('img/template.jpg', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T18:01:52.293253Z",
     "start_time": "2020-09-14T18:01:52.255997Z"
    }
   },
   "outputs": [],
   "source": [
    "from filters import cross_correlation\n",
    "\n",
    "# Perform cross-correlation between the image and the template\n",
    "out = cross_correlation(img_grey, temp_grey)\n",
    "\n",
    "# Find the location with maximum similarity\n",
    "y, x = np.unravel_index(out.argmax(), out.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(25, 20))\n",
    "\n",
    "# Display product template\n",
    "plt.subplot(311), plt.imshow(temp), plt.title('Template'), plt.axis('off') \n",
    "\n",
    "# Display image\n",
    "plt.subplot(312), plt.imshow(img), plt.title('Result (blue marker on the detected location)'), plt.axis('off')\n",
    "\n",
    "# Display cross-correlation output\n",
    "plt.subplot(313), plt.imshow(out), plt.title('Cross-correlation (white means more correlated)'), plt.axis('off')\n",
    "\n",
    "# Draw marker at detected location\n",
    "plt.plot(x, y, 'bx', ms=40, mew=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерпретация\n",
    "\n",
    "Как выглядит вывод кросс-корреляционного фильтра? Способен ли он правильно определить продукт? Объясните, какие проблемы могут возникнуть при использовании необработанного шаблона в качестве фильтра."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ваш ответ:** * Запишите ваше решение в эту ячейку с пометками.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Нулевая кросс-корреляция\n",
    "\n",
    "Решение этой проблемы заключается в вычитании среднего значения шаблона так, чтобы оно имело нулевое среднее значение.\n",
    "\n",
    "Реализуйте функцию **`zero_mean_cross_correlation`** в файле **`filters.py`** и запустите код ниже.\n",
    "\n",
    "**Если ваша реализация корректна, то вы должны увидеть синий крест по центру от правильной коробки с хлопьями**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T18:01:55.760014Z",
     "start_time": "2020-09-14T18:01:55.744070Z"
    }
   },
   "outputs": [],
   "source": [
    "from filters import zero_mean_cross_correlation\n",
    "\n",
    "# Perform cross-correlation between the image and the template\n",
    "out = zero_mean_cross_correlation(img_grey, temp_grey)\n",
    "\n",
    "# Find the location with maximum similarity\n",
    "y, x = np.unravel_index(out.argmax(), out.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30, 20))\n",
    "\n",
    "# Display product template\n",
    "plt.subplot(311), plt.imshow(temp), plt.title('Template'), plt.axis('off')\n",
    "\n",
    "# Display image\n",
    "plt.subplot(312), plt.imshow(img), plt.title('Result (blue marker on the detected location)'), plt.axis('off')\n",
    "\n",
    "# Display cross-correlation output\n",
    "plt.subplot(313), plt.imshow(out), plt.title('Cross-correlation (white means more correlated)'), plt.axis('off')\n",
    "\n",
    "# Draw marker at detcted location\n",
    "plt.plot(x, y, 'bx', ms=40, mew=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, можно определить наличие продукта с соответствующим масштабированием и пороговым значением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_product_on_shelf(shelf, product):\n",
    "    out = zero_mean_cross_correlation(shelf, product)\n",
    "    \n",
    "    # Scale output by the size of the template\n",
    "    out = out / float(product.shape[0] * product.shape[1])\n",
    "    \n",
    "    # Threshold output (this is arbitrary, you would need to tune the threshold for a real application)\n",
    "    out = out > 0.025\n",
    "    \n",
    "    if np.sum(out) > 0:\n",
    "        print('The product is on the shelf')\n",
    "    else:\n",
    "        print('The product is not on the shelf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T18:01:57.092732Z",
     "start_time": "2020-09-14T18:01:56.967795Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load image of the shelf without the product\n",
    "img2 = cv2.imread('img/shelf_soldout.jpg')\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "img2_grey = cv2.imread('img/shelf_soldout.jpg', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(img), plt.axis('off'), plt.show()\n",
    "check_product_on_shelf(img_grey, temp_grey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(img2), plt.axis('off'), plt.show()\n",
    "check_product_on_shelf(img2_grey, temp_grey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Нормализованная кросс-корреляция\n",
    "Однажды свет возле полки погаснет, и устройство слежения за продуктами начнет работать неисправно. `zero_mean_cross_correlation` не устойчива к изменению состояния освещения. Код, приведенный ниже, демонстрирует это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T18:01:59.457139Z",
     "start_time": "2020-09-14T18:01:59.423673Z"
    }
   },
   "outputs": [],
   "source": [
    "from filters import normalized_cross_correlation\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('img/shelf_dark.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_grey = cv2.imread('img/shelf_dark.jpg', 0)\n",
    "\n",
    "# Perform cross-correlation between the image and the template\n",
    "out = zero_mean_cross_correlation(img_grey, temp_grey)\n",
    "\n",
    "# Find the location with maximum similarity\n",
    "y, x = np.unravel_index(out.argmax(), out.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Display image\n",
    "plt.imshow(img), plt.title('Result (red marker on the detected location)'), plt.axis('off')\n",
    "\n",
    "# Draw marker at detcted location\n",
    "plt.plot(x, y, 'rx', ms=25, mew=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение заключается в нормализации пикселей изображения и шаблона на каждом шаге перед их сравнением. Это называется **нормализованной кросс-корреляцией**.\n",
    "\n",
    "Математическим определением нормализованной кросс-корреляции является $f$ и шаблон $g$:\n",
    "$$(f\\star{g})[m,n]=\\sum_{i,j} \\frac{f[i,j]-\\overline{f_{m,n}}}{\\sigma_{f_{m,n}}} \\cdot \\frac{g[i-m,j-n]-\\overline{g}}{\\sigma_g}$$\n",
    "\n",
    "Где:\n",
    "- $f_{m,n}$ - это патч-изображение в позиции $(m,n)$\n",
    "- $\\overline{f_{m,n}}$ - это среднее значение изображения патча $f_{m,n}$.\n",
    "- $\\sigma_{f_{m,n}}$ - стандартное отклонение изображения патча $f_{m,n}$ \n",
    "- $\\overline{g}$ - это среднее значение шаблона $g$.\n",
    "- $\\sigma_g$ - стандартное отклонение шаблона $g$.\n",
    "\n",
    "Реализуйте функцию **`normalized_cross_correlation`** в файле **`filters.py`** и запустите код ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T18:02:00.449106Z",
     "start_time": "2020-09-14T18:02:00.439654Z"
    }
   },
   "outputs": [],
   "source": [
    "from filters import normalized_cross_correlation\n",
    "\n",
    "# Perform normalized cross-correlation between the image and the template\n",
    "out = normalized_cross_correlation(img_grey, temp_grey)\n",
    "\n",
    "# Find the location with maximum similarity\n",
    "y, x = np.unravel_index(out.argmax(), out.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Display image\n",
    "plt.imshow(img), plt.title('Result (red marker on the detected location)'), plt.axis('off')\n",
    "\n",
    "# Draw marker at detcted location\n",
    "plt.plot(x, y, 'rx', ms=25, mew=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "316.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
